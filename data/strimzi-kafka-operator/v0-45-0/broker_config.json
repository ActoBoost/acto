{
    "type": "object",
    "properties": {
        "advertised.listeners": {
            "type": "string",
            "enum": [
                "PLAINTEXT://my-broker:9092"
            ],
            "description": "Listeners to publish to ZooKeeper for clients to use, if different than the listeners config property. In IaaS environments, this may need to be different from the interface to which the broker binds. If this is not set, the value for listeners will be used. Unlike listeners, it is not valid to advertise the 0.0.0.0 meta-address. Also unlike listeners, there can be duplicated ports in this property, so that one listener can be configured to advertise another listener's address. This can be useful in some cases where external load balancers are used."
        },
        "auto.create.topics.enable": {
            "type": "boolean",
            "description": "Enable auto creation of topics"
        },
        "auto.leader.rebalance.enable": {
            "type": "boolean",
            "description": "Enables auto leader balancing. A background thread checks the distribution of leaders and triggers a leader balance if required."
        },
        "background.threads": {
            "type": "integer",
            "enum": [
                10,
                20,
                0
            ],
            "description": "The number of threads to use for various background processing tasks"
        },
        "compression.type": {
            "type": "string",
            "enum": [
                "uncompressed",
                "zstd",
                "INVALID"
            ],
            "description": "Specify the final compression type for a given topic. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd', 'none'). It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer' and 'consumer' which mean the producer or consumer's compression configuration will be used."
        },
        "controller.listener.names": {
            "type": "string",
            "enum": [
                "CONTROLLER",
                "ZOOKEEPER"
            ],
            "description": "The listener that the broker will use to listen for controller traffic"
        },
        "controller.quorum.bootstrap.servers": {
            "type": "string",
            "enum": [
                "localhost:9092,localhost:9093,localhost:9094",
                "",
                "INVALID"
            ],
            "description": "The bootstrap servers for the controller quorum"
        },
        "controller.quorum.election.backoff.max.ms": {
            "type": "integer",
            "enum": [
                1000,
                10000,
                -1
            ],
            "description": "Maximum time in milliseconds before starting new elections. This is used in the binary exponential backoff mechanism that helps prevent gridlocked elections"
        },
        "controller.quorum.election.timeout.ms": {
            "type": "integer",
            "enum": [
                1000,
                10000,
                -1
            ],
            "description": "The maximum time in milliseconds that the controller can delay the beginning of an election"
        },
        "controller.quorum.fetch.timeout.ms": {
            "type": "integer",
            "enum": [
                1000,
                10000,
                -1
            ],
            "description": "Maximum time without a successful fetch from the current leader before becoming a candidate and triggering an election for voters; Maximum time a leader can go without receiving valid fetch or fetchSnapshot request from a majority of the quorum before resigning."
        },
        "controller.quorum.voters": {
            "type": "string",
            "enum": [
                "1@localhost:9092,2@localhost:9093,3@localhost:9094",
                "",
                "INVALID"
            ],
            "description": "The broker ids of the voters in the controller quorum"
        },
        "delete.topic.enable": {
            "type": "boolean",
            "description": "Enables topic deletion"
        },
        "early.start.listeners": {
            "type": "string",
            "enum": [
                "PLAINTEXT://my-broker:9092"
            ],
            "description": "A comma-separated list of listener names which may be started before the authorizer has finished initialization. This is useful when the authorizer is dependent on the cluster itself for bootstrapping, as is the case for the StandardAuthorizer (which stores ACLs in the metadata log.) By default, all listeners included in controller.listener.names will also be early start listeners. A listener should not appear in this list if it accepts external traffic."
        },
        "eligible.leader.replicas.enable": {
            "type": "boolean",
            "description": "Enable the Eligible leader replicas"
        },
        "leader.imbalance.check.interval.seconds": {
            "type": "integer",
            "enum": [
                300,
                600,
                0
            ],
            "description": "The frequency with which the partition rebalance check is triggered by the controller"
        },
        "leader.imbalance.per.broker.percentage": {
            "type": "integer",
            "enum": [
                10,
                20,
                0
            ],
            "description": "The ratio of leader imbalance allowed per broker. The controller would trigger a leader balance if it goes above this value per broker. The value is specified in percentage."
        },
        "listeners": {
            "type": "string",
            "enum": [
                "PLAINTEXT://my-broker:9092",
                ""
            ],
            "description": "Listener List"
        },
        "log.dir": {
            "type": "string",
            "enum": [
                "/tmp/kafka-logs",
                "/kafka-logs",
                "INVALID"
            ],
            "description": "The directory in which the log data is kept (supplemental for log.dirs property)"
        },
        "log.dirs": {
            "type": "string",
            "enum": [
                "/tmp/kafka-logs",
                "/kafka-logs",
                "INVALID"
            ],
            "description": "A comma separated list of directories under which to store log files"
        },
        "log.flush.interval.messages": {
            "type": "integer",
            "enum": [
                10000,
                9223372036854775807,
                0
            ],
            "description": "The number of messages accumulated on a log partition before messages are flushed to disk"
        },
        "log.flush.interval.ms": {
            "type": "integer",
            "enum": [
                1000,
                9223372036854775807,
                -1
            ],
            "description": "The maximum time in ms that a message in any topic is kept in memory before flushed to disk"
        },
        "log.flush.offset.checkpoint.interval.ms": {
            "type": "integer",
            "enum": [
                60000,
                9223372036854775807,
                -1
            ],
            "description": "The frequency with which the log flusher checks whether any log is eligible for deletion"
        },
        "log.flush.scheduler.interval.ms": {
            "type": "integer",
            "enum": [
                9223372036854775807,
                1000,
                -1
            ],
            "description": "The frequency in ms that the log flusher checks whether any log needs to be flushed to disk"
        },
        "log.flush.start.offset.checkpoint.interval.ms": {
            "type": "integer",
            "enum": [
                60000,
                9223372036854775807,
                -1
            ],
            "description": "The frequency with which we update the persistent record of log start offset"
        },
        "log.retention.bytes": {
            "type": "integer",
            "enum": [
                -1,
                1073741824,
                0
            ],
            "description": "The maximum size of the log before deleting it"
        },
        "log.retention.hours": {
            "type": "integer",
            "enum": [
                168,
                0,
                -1
            ],
            "description": "The number of hours to keep a log file before deleting it (in hours), tertiary to log.retention.ms property"
        },
        "log.retention.minutes": {
            "type": "integer",
            "enum": [
                10080,
                0,
                -1
            ],
            "description": "The number of minutes to keep a log file before deleting it (in minutes), secondary to log.retention.ms property"
        },
        "log.retention.ms": {
            "type": "integer",
            "enum": [
                604800000,
                0,
                -1
            ],
            "description": "The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied."
        },
        "log.roll.hours": {
            "type": "integer",
            "enum": [
                168,
                0,
                -1
            ],
            "description": "The maximum time before a new log segment is rolled out (in hours), tertiary to log.roll.ms property"
        },
        "log.roll.jitter.hours": {
            "type": "integer",
            "enum": [
                0,
                1,
                -1
            ],
            "description": "The maximum jitter to subtract from logRollTime (in hours), secondary to log.roll.ms property"
        },
        "log.roll.jitter.ms": {
            "type": "integer",
            "enum": [
                0,
                1,
                -1
            ],
            "description": "The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used."
        },
        "log.roll.ms": {
            "type": "integer",
            "enum": [
                604800000,
                1,
                -1
            ],
            "description": "The maximum time before a new log segment is rolled out (in milliseconds), If not set, the value in log.roll.hours is used. If set to -1, no time limit is applied."
        },
        "log.segment.bytes": {
            "type": "integer",
            "enum": [
                1073741824,
                104857600,
                0
            ],
            "description": "The maximum size of a log segment file. When this size is reached a new log segment will be created."
        },
        "log.segment.delete.delay.ms": {
            "type": "integer",
            "enum": [
                60000,
                9223372036854775807,
                -1
            ],
            "description": "The amount of time to wait before deleting a file from the filesystem"
        },
        "message.max.bytes": {
            "type": "integer",
            "enum": [
                1048588,
                1000000,
                0
            ],
            "description": "The largest record batch size allowed by Kafka. If this is increased and there are consumers older than 0.10.2, the consumers' fetch size must also be increased so that the they can fetch record batches this large."
        },
        "metadata.log.dir": {
            "type": "string",
            "enum": [
                "/tmp/kafka-logs",
                "/kafka-logs",
                "INVALID"
            ],
            "description": "This configuration determines where we put the metadata log for clusters in KRaft mode. If it is not set, the metadata log is placed in the first log directory from log.dirs."
        },
        "metadata.log.max.record.bytes.between.snapshots": {
            "type": "integer",
            "enum": [
                9223372036854775807,
                1048576,
                0
            ],
            "description": "This is the maximum number of bytes in the log between the latest snapshot and the high-watermark needed before generating a new snapshot. The default value is 20971520."
        },
        "metadata.log.max.snapshot.interval.ms": {
            "type": "integer",
            "enum": [
                60000,
                9223372036854775807,
                -1
            ],
            "description": "This is the maximum number of milliseconds to wait to generate a snapshot if there are committed records in the log that are not included in the latest snapshot. A value of zero disables time based snapshot generation. The default value is 3600000."
        },
        "metadata.log.segment.bytes": {
            "type": "integer",
            "enum": [
                104857600,
                1073741824,
                0
            ],
            "description": "The maximum size of a metadata log segment file. When this size is reached a new log segment will be created."
        },
        "metadata.log.segment.ms": {
            "type": "integer",
            "enum": [
                604800000,
                6048,
                -1
            ],
            "description": "The maximum time before a new log segment is rolled out (in milliseconds), If not set, the value in log.roll.hours is used. If set to -1, no time limit is applied."
        },
        "metadata.max.retention.bytes": {
            "type": "integer",
            "enum": [
                104857600,
                1073741824,
                -1
            ],
            "description": "The maximum size of the metadata log before deleting it"
        },
        "metadata.max.retention.ms": {
            "type": "integer",
            "enum": [
                604800000,
                0,
                -1
            ],
            "description": "The number of milliseconds to keep a metadata log file or snapshot before deleting it. Since at least one snapshot must exist before any logs can be deleted, this is a soft limit."
        },
        "min.insync.replicas": {
            "type": "integer",
            "enum": [
                1,
                2,
                0
            ],
            "description": "When a producer sets acks to 'all' (or '-1'), this configuration specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend)."
        },
        "node.id": {
            "type": "integer",
            "enum": [
                0,
                -1,
                1
            ],
            "description": "The broker id"
        },
        "num.io.threads": {
            "type": "integer",
            "enum": [
                8,
                16,
                0
            ],
            "description": "The number of threads that the server uses for processing requests"
        },
        "num.network.threads": {
            "type": "integer",
            "enum": [
                3,
                2,
                0
            ],
            "description": "The number of network threads that the server uses for handling network requests"
        },
        "num.recovery.threads.per.data.dir": {
            "type": "integer",
            "enum": [
                1,
                2,
                0
            ],
            "description": "The number of threads per data directory to be used for log recovery at startup and flushing at shutdown"
        },
        "num.replica.alter.log.dirs.threads": {
            "type": "integer",
            "enum": [
                20,
                10,
                0
            ],
            "description": "The number of threads that can move replicas between log directories, which may include disk I/O"
        },
        "num.replica.fetchers": {
            "type": "integer",
            "enum": [
                1,
                2,
                0
            ],
            "description": "The number of threads to use for fetching log segments from replicas. If there are fewer threads than partitions, a single thread will be used to fetch log segments from multiple partitions"
        },
        "offset.metadata.max.bytes": {
            "type": "integer",
            "enum": [
                4096,
                4097,
                0
            ],
            "description": "The maximum size for a metadata entry associated with an offset commit"
        },
        "offsets.commit.timeout.ms": {
            "type": "integer",
            "enum": [
                5000,
                60000,
                0
            ],
            "description": "Offset commit will be delayed until all replicas for the offsets topic receive the commit or this timeout is reached. This is similar to the producer request timeout."
        },
        "offsets.load.buffer.size": {
            "type": "integer",
            "enum": [
                5242880,
                5242,
                0
            ],
            "description": "Batch size for reading from the offsets segments when loading offsets into the cache (soft-limit, overridden if records are too large)."
        },
        "offsets.retention.check.interval.ms": {
            "type": "integer",
            "enum": [
                600000,
                60000,
                0
            ],
            "description": "Frequency at which to check for stale offsets"
        },
        "offsets.retention.minutes": {
            "type": "integer",
            "enum": [
                10080,
                10000,
                0
            ],
            "description": "For subscribed consumers, committed offset of a specific partition will be expired and discarded when 1) this retention period has elapsed after the consumer group loses all its consumers (i.e. becomes empty); 2) this retention period has elapsed since the last time an offset is committed for the partition and the group is no longer subscribed to the corresponding topic."
        },
        "offsets.topic.compression.codec": {
            "type": "integer",
            "enum": [
                0,
                1,
                -1
            ],
            "description": "Compression codec for the offsets topic - compression may be used to achieve atomic commits."
        },
        "offsets.topic.num.partitions": {
            "type": "integer",
            "enum": [
                50,
                1,
                0
            ],
            "description": "The number of partitions for the offset commit topic (should not change after deployment)"
        },
        "offsets.topic.replication.factor": {
            "type": "integer",
            "enum": [
                3,
                1,
                0
            ],
            "description": "The replication factor for the offsets topic (set higher to ensure availability). Internal topic creation will fail until the cluster size meets this replication factor requirement."
        },
        "offsets.topic.segment.bytes": {
            "type": "integer",
            "enum": [
                104857600,
                1073741824,
                0
            ],
            "description": "The offsets topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads"
        },
        "process.roles": {
            "type": "string",
            "enum": [
                "broker",
                "controller",
                "broker,controller"
            ],
            "description": "The roles that this process plays: 'broker', 'controller', or 'broker,controller' if it is both."
        },
        "queued.max.requests": {
            "type": "integer",
            "enum": [
                500,
                1000,
                0
            ],
            "description": "The number of queued requests allowed for data-plane, before blocking the network threads"
        },
        "replica.fetch.min.bytes": {
            "type": "integer",
            "enum": [
                1,
                1000,
                -1
            ],
            "description": "Minimum bytes expected for each fetch response. If not enough bytes, wait up to replica.fetch.wait.max.ms (broker config)."
        },
        "replica.fetch.wait.max.ms": {
            "type": "integer",
            "enum": [
                500,
                1000,
                0
            ],
            "description": "The maximum wait time for each fetcher request issued by follower replicas. This value should always be less than the replica.lag.time.max.ms at all times to prevent frequent shrinking of ISR for low throughput topics"
        },
        "replica.high.watermark.checkpoint.interval.ms": {
            "type": "integer",
            "enum": [
                5000,
                1000,
                0
            ],
            "description": "The frequency with which the high watermark is saved out to disk"
        },
        "replica.lag.time.max.ms": {
            "type": "integer",
            "enum": [
                10000,
                5000,
                0
            ],
            "description": "If a follower hasn't sent any fetch requests or hasn't consumed up to the leaders log end offset for at least this time, the leader will remove the follower from isr"
        },
        "replica.socket.receive.buffer.bytes": {
            "type": "integer",
            "enum": [
                102400,
                1024,
                0
            ],
            "description": "The socket receive buffer for network requests"
        },
        "replica.socket.timeout.ms": {
            "type": "integer",
            "enum": [
                30000,
                1000,
                0
            ],
            "description": "The socket timeout for network requests. The actual timeout set will be max.fetch.wait + replica.socket.timeout.ms"
        },
        "request.timeout.ms": {
            "type": "integer",
            "enum": [
                30000,
                1000,
                0
            ],
            "description": "The configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted."
        },
        "sasl.mechanism.controller.protocol": {
            "type": "string",
            "enum": [
                "PLAIN",
                "GSSAPI",
                "INVALID"
            ],
            "description": "The SASL mechanism to use for the controller protocol"
        },
        "socket.receive.buffer.bytes": {
            "type": "integer",
            "enum": [
                102400,
                -1,
                0
            ],
            "description": "The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used."
        },
        "socket.request.max.bytes": {
            "type": "integer",
            "enum": [
                104857600,
                1048576,
                0
            ],
            "description": "The maximum number of bytes in a socket request"
        },
        "socket.send.buffer.bytes": {
            "type": "integer",
            "enum": [
                102400,
                -1,
                0
            ],
            "description": "The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used."
        },
        "transaction.max.timeout.ms": {
            "type": "integer",
            "enum": [
                900000,
                60000,
                0
            ],
            "description": "The maximum allowed time for a transaction to complete (in milliseconds)."
        },
        "transaction.state.log.load.buffer.size": {
            "type": "integer",
            "enum": [
                5242880,
                5242,
                0
            ],
            "description": "Batch size for reading from the transaction log segments when loading producer ids and transactions into the cache (soft-limit, overridden if records are too large)."
        },
        "transaction.state.log.min.isr": {
            "type": "integer",
            "enum": [
                1,
                2,
                0
            ],
            "description": "The minimum number of replicas that must acknowledge a transactional message"
        },
        "transaction.state.log.num.partitions": {
            "type": "integer",
            "enum": [
                50,
                1,
                0
            ],
            "description": "The number of partitions for the transaction state topic (should not change after deployment)"
        },
        "transaction.state.log.replication.factor": {
            "type": "integer",
            "enum": [
                3,
                1,
                0
            ],
            "description": "The replication factor for the transaction state topic (set higher to ensure availability). Internal topic creation will fail until the cluster size meets this replication factor requirement."
        },
        "transaction.state.log.segment.bytes": {
            "type": "integer",
            "enum": [
                104857600,
                1073741824,
                0
            ],
            "description": "The transaction log segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads"
        },
        "transactional.id.expiration.ms": {
            "type": "integer",
            "enum": [
                604800000,
                60480000,
                0
            ],
            "description": "The time in ms that the transaction coordinator will wait without receiving any transaction status updates for the current transaction before expiring its transactional id. Transactional IDs will not expire while a the transaction is still ongoing."
        },
        "unclean.leader.election.enable": {
            "type": "boolean",
            "description": "Indicates whether to enable replicas not in the ISR set to be elected as leader as a last resort, even though doing so may result in data loss"
        },
        "broker.heartbeat.interval.ms": {
            "type": "integer",
            "enum": [
                3000,
                1000,
                0
            ],
            "description": "The frequency with which the broker sends the group coordinator heartbeat"
        },
        "broker.id.generation.enable": {
            "type": "boolean",
            "description": "Enable automatic broker id generation on the server"
        },
        "broker.rack": {
            "type": "string",
            "enum": [
                "rack1",
                "rack2",
                "INVALID"
            ],
            "description": "The rack of the broker"
        },
        "broker.session.timeout.ms": {
            "type": "integer",
            "enum": [
                10000,
                30000,
                0
            ],
            "description": "The timeout used to detect broker failures when using Kafka's group management facilities"
        },
        "compression.gzip.level": {
            "type": "integer",
            "enum": [
                3,
                9,
                0
            ],
            "description": "Specify the level of compression for the gzip compression codec. This is the pass through to the java.util.zip.GZIPOutputStream"
        },
        "compression.lz4.level": {
            "type": "integer",
            "enum": [
                1,
                9,
                0
            ],
            "description": "Specify the level of compression for the lz4 compression codec. This is the pass through to the net.jpountz.lz4.LZ4Factory"
        },
        "compression.zstd.level": {
            "type": "integer",
            "enum": [
                3,
                22,
                0
            ],
            "description": "Specify the level of compression for the zstd compression codec. This is the pass through to the com.github.luben.zstd.Zstd"
        },
        "connections.max.idle.ms": {
            "type": "integer",
            "enum": [
                540000,
                54000,
                0
            ],
            "description": "Idle connections timeout: the server socket processor threads close the connections that idle more than this"
        },
        "connections.max.reauth.ms": {
            "type": "integer",
            "enum": [
                0,
                1000,
                -1
            ],
            "description": "When explicitly set to a positive number (the default is 0, not a positive number), a session lifetime that will not exceed the configured value will be communicated to v2.2.0 or later clients when they authenticate."
        },
        "controlled.shutdown.enable": {
            "type": "boolean",
            "description": "Enable controlled shutdown of the broker"
        },
        "controlled.shutdown.max.retries": {
            "type": "integer",
            "enum": [
                3,
                5,
                0
            ],
            "description": "Controlled shutdown can fail for multiple reasons. This determines the number of retries when such failure happens"
        },
        "controlled.shutdown.retry.backoff.ms": {
            "type": "integer",
            "enum": [
                5000,
                1000,
                0
            ],
            "description": "Before each controlled shutdown, the controller must confirm that the broker is the leader for all partitions it hosts. This is the maximum time the controller waits for the broker to become the leader."
        },
        "controller.quorum.append.linger.ms": {
            "type": "integer",
            "enum": [
                1000,
                10000,
                0
            ],
            "description": "The amount of time to wait before sending a new append to the controller quorum"
        },
        "controller.quorum.request.timeout.ms": {
            "type": "integer",
            "enum": [
                1000,
                10000,
                0
            ],
            "description": "The configuration controls the maximum amount of time the client will wait for the response of a request."
        },
        "controller.socket.timeout.ms": {
            "type": "integer",
            "enum": [
                30000,
                1000,
                0
            ],
            "description": "The socket timeout for controller-to-controller communication"
        },
        "default.replication.factor": {
            "type": "integer",
            "enum": [
                1,
                3,
                0
            ],
            "description": "The default replication factor for automatically created topics"
        },
        "delegation.token.expiry.time.ms": {
            "type": "integer",
            "enum": [
                86400000,
                8640000,
                0
            ],
            "description": "The token validity time in milliseconds before the token needs to be renewed. Default value 1 day."
        },
        "delegation.token.max.lifetime.ms": {
            "type": "integer",
            "enum": [
                604800000,
                60480000,
                0
            ],
            "description": "The maximum lifetime of a token in milliseconds. Default value 7 days."
        },
        "delegation.token.secret.key": {
            "type": "string",
            "enum": [
                "password",
                "INVALID"
            ],
            "description": "The secret key used to sign the token"
        },
        "delete.records.purgatory.purge.interval.requests": {
            "type": "integer",
            "enum": [
                1,
                10,
                0
            ],
            "description": "The purge interval (in number of requests) of the delete records request purgatory"
        },
        "fetch.max.bytes": {
            "type": "integer",
            "enum": [
                52428800,
                5242880,
                0
            ],
            "description": "The maximum number of bytes we will return for a fetch request. Must be at least 1024."
        },
        "fetch.purgatory.purge.interval.requests": {
            "type": "integer",
            "enum": [
                1,
                10,
                0
            ],
            "description": "The purge interval (in number of requests) of the fetch request purgatory"
        },
        "group.consumer.assignors": {
            "type": "string",
            "enum": [
                "org.apache.kafka.coordinator.group.assignor.RangeAssignor",
                "org.apache.kafka.coordinator.group.assignor.UniformAssignor",
                "INVALID"
            ],
            "description": "The consumer group assignor to use for new consumer groups"
        },
        "group.consumer.heartbeat.interval.ms": {
            "type": "integer",
            "enum": [
                5000,
                10000,
                0
            ],
            "description": "The frequency with which the consumer coordinator checks the liveness of the consumer"
        },
        "group.consumer.max.heartbeat.interval.ms": {
            "type": "integer",
            "enum": [
                30000,
                10000,
                0
            ],
            "description": "The maximum time that the consumer expects a response from the consumer coordinator"
        },
        "group.consumer.max.session.timeout.ms": {
            "type": "integer",
            "enum": [
                45000,
                90000,
                0
            ],
            "description": "The maximum allowed session timeout for registered consumers"
        },
        "group.consumer.max.size": {
            "type": "integer",
            "enum": [
                1000,
                10000,
                0
            ],
            "description": "The maximum number of consumers that a single consumer group can accommodate. This value will only impact the new consumer coordinator. To configure the classic consumer coordinator check group.max.size instead."
        },
        "group.consumer.min.heartbeat.interval.ms": {
            "type": "integer",
            "enum": [
                1000,
                3000,
                0
            ],
            "description": "The minimum allowed time between heartbeats"
        },
        "group.consumer.min.session.timeout.ms": {
            "type": "integer",
            "enum": [
                10000,
                30000,
                0
            ],
            "description": "The minimum allowed session timeout for registered consumers"
        },
        "group.consumer.session.timeout.ms": {
            "type": "integer",
            "enum": [
                45000,
                90000,
                0
            ],
            "description": "The timeout to detect client failures when using the consumer group protocol."
        },
        "group.coordinator.append.linger.ms": {
            "type": "integer",
            "enum": [
                1000,
                10000,
                0
            ],
            "description": "The duration in milliseconds that the coordinator will wait for writes to accumulate before flushing them to disk. Transactional writes are not accumulated."
        },
        "group.coordinator.rebalance.protocols": {
            "type": "string",
            "enum": [
                "consumer",
                "classic",
                "INVALID"
            ],
            "description": "The rebalance protocol to use for new consumer groups"
        },
        "group.coordinator.threads": {
            "type": "integer",
            "enum": [
                10,
                20,
                0
            ],
            "description": "The number of threads used by the group coordinator."
        },
        "group.initial.rebalance.delay.ms": {
            "type": "integer",
            "enum": [
                3000,
                1000,
                0
            ],
            "description": "The amount of time the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins."
        },
        "group.max.session.timeout.ms": {
            "type": "integer",
            "enum": [
                30000,
                10000,
                0
            ],
            "description": "The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures."
        },
        "group.max.size": {
            "type": "integer",
            "enum": [
                1000,
                10000,
                0
            ],
            "description": "The maximum number of consumers that a single consumer group can accommodate."
        },
        "group.min.session.timeout.ms": {
            "type": "integer",
            "enum": [
                10000,
                30000,
                0
            ],
            "description": "The minimum allowed session timeout for registered consumers. Shorter timeouts give quicker failure detection at the cost of more frequent rebalances."
        },
        "group.share.delivery.count.limit": {
            "type": "integer",
            "enum": [
                2,
                10,
                0
            ],
            "description": "The maximum number of messages that can be delivered to a consumer in a single poll."
        },
        "group.share.heartbeat.interval.ms": {
            "type": "integer",
            "enum": [
                5000,
                10000,
                0
            ],
            "description": "The heartbeat interval given to the members of a share group."
        },
        "group.share.max.groups": {
            "type": "integer",
            "enum": [
                1,
                10,
                0
            ],
            "description": "The maximum number of share groups that can be active at the same time."
        },
        "group.share.max.heartbeat.interval.ms": {
            "type": "integer",
            "enum": [
                30000,
                10000,
                0
            ],
            "description": "The maximum heartbeat interval for share group members."
        },
        "group.share.max.record.lock.duration.ms": {
            "type": "integer",
            "enum": [
                30000,
                60000,
                0
            ],
            "description": "The record acquisition lock maximum duration in milliseconds for share groups."
        },
        "group.share.max.session.timeout.ms": {
            "type": "integer",
            "enum": [
                45000,
                90000,
                0
            ],
            "description": "The maximum session timeout for share group members."
        },
        "group.share.max.size": {
            "type": "integer",
            "enum": [
                1000,
                10,
                0
            ],
            "description": "The maximum number of consumers that a single share group can accommodate."
        },
        "group.share.min.heartbeat.interval.ms": {
            "type": "integer",
            "enum": [
                1000,
                3000,
                0
            ],
            "description": "The minimum heartbeat interval for share group members."
        },
        "group.share.min.record.lock.duration.ms": {
            "type": "integer",
            "enum": [
                1000,
                3000,
                0
            ],
            "description": "The record acquisition lock minimum duration in milliseconds for share groups."
        },
        "group.share.min.session.timeout.ms": {
            "type": "integer",
            "enum": [
                45000,
                90000,
                0
            ],
            "description": "The minimum allowed session timeout for share group members."
        },
        "group.share.partition.max.record.locks": {
            "type": "integer",
            "enum": [
                1000,
                100,
                0
            ],
            "description": "The maximum number of record locks that can be held by a single consumer in a share group."
        },
        "group.share.record.lock.duration.ms": {
            "type": "integer",
            "enum": [
                15000,
                30000,
                0
            ],
            "description": "The record acquisition lock duration in milliseconds for share groups."
        },
        "group.share.session.timeout.ms": {
            "type": "integer",
            "enum": [
                10000,
                30000,
                0
            ],
            "description": "The timeout to detect client failures when using the share group protocol."
        },
        "initial.broker.registration.timeout.ms": {
            "type": "integer",
            "enum": [
                60000,
                1000,
                0
            ],
            "description": "When initially registering with the controller quorum, the number of milliseconds to wait before declaring failure and exiting the broker process."
        },
        "inter.broker.listener.name": {
            "type": "string",
            "enum": [
                "PLAINTEXT",
                "SSL",
                "INVALID"
            ],
            "description": "Name of listener used for communication between brokers. If this is unset, the listener name is defined by security.inter.broker.protocolIt is an error to set this and security.inter.broker.protocol properties at the same time."
        },
        "inter.broker.protocol.version": {
            "type": "string",
            "enum": [
                "3.9-IV0",
                "4.0-IV1"
            ],
            "description": "Specify which version of the inter-broker protocol will be used."
        },
        "log.cleaner.backoff.ms": {
            "type": "integer",
            "enum": [
                15000,
                1000,
                0
            ],
            "description": "The amount of time to sleep when there are no logs to clean"
        },
        "log.cleaner.dedupe.buffer.size": {
            "type": "integer",
            "enum": [
                134217728,
                13421772,
                0
            ],
            "description": "The size of the buffer to use for deduplication"
        },
        "log.cleaner.delete.retention.ms": {
            "type": "integer",
            "enum": [
                86400000,
                8640000,
                -1
            ],
            "description": "The amount of time to retain tombstone message markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise tombstones messages may be collected before a consumer completes their scan)."
        },
        "log.cleaner.enable": {
            "type": "boolean",
            "description": "Enable the log cleaner process to run on the server"
        },
        "log.cleaner.io.buffer.load.factor": {
            "type": "number",
            "enum": [
                0.9,
                0.8,
                0.0
            ],
            "description": "The load factor of the log cleaner IO buffer pool"
        },
        "log.cleaner.io.buffer.size": {
            "type": "integer",
            "enum": [
                52428800,
                5242880,
                -1
            ],
            "description": "The total memory used for log cleaner I/O buffers across all cleaner threads"
        },
        "log.cleaner.io.max.bytes.per.second": {
            "type": "integer",
            "enum": [
                104857600,
                10485760,
                0
            ],
            "description": "The maximum I/O rate for the cleaner in bytes per second"
        },
        "log.cleaner.max.compaction.lag.ms": {
            "type": "integer",
            "enum": [
                9223372036854775807,
                1000,
                0
            ],
            "description": "The maximum time a message will remain ineligible for compaction in the log. Only applicable for logs that are being compacted."
        },
        "log.cleaner.min.cleanable.ratio": {
            "type": "number",
            "enum": [
                0.5,
                0.1,
                -1.0
            ],
            "description": "The minimum ratio of dirty log to total log for a log to eligible for cleaning"
        },
        "log.cleaner.min.compaction.lag.ms": {
            "type": "integer",
            "enum": [
                0,
                1000,
                -1
            ],
            "description": "The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted."
        },
        "log.cleaner.threads": {
            "type": "integer",
            "enum": [
                1,
                2,
                -1
            ],
            "description": "The number of background threads to use for log cleaning"
        },
        "log.cleanup.policy": {
            "type": "string",
            "enum": [
                "delete",
                "compact",
                "INVALID"
            ],
            "description": "The default cleanup policy for segments beyond the retention window. A comma separated list of valid policies. Valid policies are: delete and compact"
        },
        "log.index.interval.bytes": {
            "type": "integer",
            "enum": [
                4096,
                4097,
                -1
            ],
            "description": "The interval with which we add an entry to the offset index"
        },
        "log.index.size.max.bytes": {
            "type": "integer",
            "enum": [
                10485760,
                1048576,
                0
            ],
            "description": "The maximum size in bytes of the offset index"
        },
        "log.local.retention.bytes": {
            "type": "integer",
            "enum": [
                -1,
                104857600,
                0
            ],
            "description": "The maximum size of the log before deleting it"
        },
        "log.local.retention.ms": {
            "type": "integer",
            "enum": [
                604800000,
                0,
                -1
            ],
            "description": "The number of milliseconds to keep the local log segments before it gets eligible for deletion. Default value is -2, it represents `log.retention.ms` value is to be used. The effective value should always be less than or equal to `log.retention.ms` value."
        },
        "log.message.format.version": {
            "type": "string",
            "enum": [
                "3.9-IV0",
                "4.0-IV1"
            ],
            "description": "Specify the message format version the broker will use to append messages to the logs. The value should be a valid MetadataVersion"
        },
        "log.message.timestamp.after.max.ms": {
            "type": "integer",
            "enum": [
                9223372036854775807,
                1000,
                -1
            ],
            "description": "The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message"
        },
        "log.message.timestamp.before.max.ms": {
            "type": "integer",
            "enum": [
                9223372036854775807,
                1000,
                -1
            ],
            "description": "This configuration sets the allowable timestamp difference between the broker's timestamp and the message timestamp. The message timestamp can be earlier than or equal to the broker's timestamp, with the maximum allowable difference determined by the value set in this configuration."
        },
        "log.message.timestamp.type": {
            "type": "string",
            "enum": [
                "CreateTime",
                "LogAppendTime",
                "INVALID"
            ],
            "description": "Define whether the timestamp in the message is message create time or log append time"
        },
        "log.preallocate": {
            "type": "boolean",
            "description": "Should pre allocate file when create new segment?"
        },
        "log.retention.check.interval.ms": {
            "type": "integer",
            "enum": [
                300000,
                30000,
                0
            ],
            "description": "The frequency with which we check whether any log segment is eligible for deletion"
        },
        "max.connection.creation.rate": {
            "type": "integer",
            "enum": [
                50,
                100,
                -1
            ],
            "description": "The maximum connection creation rate we allow in the broker at any time. Listener-level limits may also be configured by prefixing the config name with the listener prefix, for example, listener.name.internal.max.connection.creation.rate.Broker-wide connection rate limit should be configured based on broker capacity while listener limits should be configured based on application requirements."
        },
        "max.connections": {
            "type": "integer",
            "enum": [
                2147483647,
                100,
                -1
            ],
            "description": "The maximum number of connections we allow in the broker at any time. Listener-level limits may also be configured by prefixing the config name with the listener prefix, for example, listener.name.internal.max.connections.Broker-wide connection limit should be configured based on broker capacity while listener limits should be configured based on application requirements."
        },
        "max.connections.per.ip": {
            "type": "integer",
            "enum": [
                2147483647,
                100,
                -1
            ],
            "description": "The maximum number of connections we allow from each ip address. This limit is applied globally. Listener-level limits may also be configured by prefixing the config name with the listener prefix, for example, listener.name.internal.max.connections.per.ip.Broker-wide connection limit should be configured based on broker capacity while listener limits should be configured based on application requirements."
        },
        "max.connections.per.ip.overrides": {
            "type": "string",
            "enum": [
                "127.0.0.1:200",
                "127.0.0.1:2000",
                "INVALID"
            ],
            "description": "A comma-separated list of per-ip or hostname overrides to the default maximum number of connections. An example value is 'hostName:100,127.0.0.1:200'"
        },
        "max.incremental.fetch.session.cache.slots": {
            "type": "integer",
            "enum": [
                1000,
                100,
                -1
            ],
            "description": "The maximum number of total incremental fetch sessions that we will maintain."
        },
        "max.request.partition.size.limit": {
            "type": "integer",
            "enum": [
                2000,
                1048576,
                0
            ],
            "description": "The maximum number of partitions can be served in one request."
        },
        "num.partitions": {
            "type": "integer",
            "enum": [
                1,
                3,
                0
            ],
            "description": "The default number of log partitions per topic"
        },
        "password.encoder.old.secret": {
            "type": "string",
            "enum": [
                "password",
                "INVALID"
            ],
            "description": "The old secret used to encode the password"
        },
        "password.encoder.secret": {
            "type": "string",
            "enum": [
                "password",
                "INVALID"
            ],
            "description": "The secret used to encode the password"
        },
        "principal.builder.class": {
            "type": "string",
            "enum": [
                "org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder",
                "INVALID"
            ],
            "description": "The fully qualified name of a class that implements the KafkaPrincipalBuilder interface, which is used to build the KafkaPrincipal object used during authorization. If no principal builder is defined, the default behavior depends on the security protocol in use. For SSL authentication, the principal will be derived using the rules defined by"
        },
        "producer.purgatory.purge.interval.requests": {
            "type": "integer",
            "enum": [
                1,
                10,
                0
            ],
            "description": "The purge interval (in number of requests) of the producer request purgatory"
        },
        "queued.max.request.bytes": {
            "type": "integer",
            "enum": [
                104857600,
                209715200,
                0
            ],
            "description": "The number of queued requests allowed for data-plane, before blocking the network threads"
        },
        "remote.fetch.max.wait.ms": {
            "type": "integer",
            "enum": [
                500,
                1000,
                0
            ],
            "description": "The maximum amount of time the server will wait before answering the remote fetch request"
        },
        "remote.log.manager.copier.thread.pool.size": {
            "type": "integer",
            "enum": [
                10,
                20,
                0
            ],
            "description": "The number of threads used by the remote log manager copier"
        },
        "remote.log.manager.copy.max.bytes.per.second": {
            "type": "integer",
            "enum": [
                104857600,
                10485760,
                0
            ],
            "description": "The maximum number of bytes that can be copied from local storage to remote storage per second. This is a global limit for all the partitions that are being copied from local storage to remote storage. The default value is Long.MAX_VALUE, which means there is no limit on the number of bytes that can be copied per second."
        },
        "remote.log.manager.copy.quota.window.num": {
            "type": "integer",
            "enum": [
                10,
                20,
                0
            ],
            "description": "The number of samples to retain in memory for remote copy quota management. The default value is 11, which means there are 10 whole windows + 1 current window."
        },
        "remote.log.manager.copy.quota.window.size.seconds": {
            "type": "integer",
            "enum": [
                60,
                10,
                0
            ],
            "description": "The time span of each sample for remote copy quota management. The default value is 1 second."
        },
        "remote.log.manager.expiration.thread.pool.size": {
            "type": "integer",
            "enum": [
                10,
                20,
                0
            ],
            "description": "Size of the thread pool used in scheduling tasks to clean up remote log segments. The default value of -1 means that this will be set to the configured value of remote.log.manager.thread.pool.size, if available; otherwise, it defaults to 10."
        },
        "remote.log.manager.fetch.max.bytes.per.second": {
            "type": "integer",
            "enum": [
                104857600,
                10485760,
                0
            ],
            "description": "The maximum number of bytes that can be fetched from remote storage to local storage per second. This is a global limit for all the partitions that are being fetched from remote storage to local storage. The default value is Long.MAX_VALUE, which means there is no limit on the number of bytes that can be fetched per second."
        },
        "remote.log.manager.fetch.quota.window.num": {
            "type": "integer",
            "enum": [
                10,
                20,
                0
            ],
            "description": "The number of samples to retain in memory for remote fetch quota management. The default value is 11, which means there are 10 whole windows + 1 current window."
        },
        "remote.log.manager.fetch.quota.window.size.seconds": {
            "type": "integer",
            "enum": [
                60,
                10,
                0
            ],
            "description": "The time span of each sample for remote fetch quota management. The default value is 1 second."
        },
        "remote.log.metadata.manager.class.name": {
            "type": "string",
            "enum": [
                "org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager",
                "INVALID"
            ],
            "description": "Fully qualified class name of `RemoteLogMetadataManager` implementation."
        },
        "remote.log.metadata.manager.class.path": {
            "type": "string",
            "enum": [
                "INVALID"
            ],
            "description": "Path to the jar file containing the `RemoteLogMetadataManager` implementation."
        },
        "remote.log.metadata.manager.impl.prefix": {
            "type": "string",
            "enum": [
                "rlmm.config.",
                "INVALID"
            ],
            "description": "Prefix used for properties to be passed to RemoteLogMetadataManager implementation. For example this value can be `rlmm.config.`"
        },
        "remote.log.metadata.manager.listener.name": {
            "type": "string",
            "enum": [
                "PLAINTEXT",
                "SSL",
                "INVALID"
            ],
            "description": "Listener name of the local broker to which it should get connected if needed by RemoteLogMetadataManager implementation."
        },
        "remote.log.reader.max.pending.tasks": {
            "type": "integer",
            "enum": [
                100,
                1000,
                0
            ],
            "description": "Maximum remote log reader thread pool task queue size. If the task queue is full, fetch requests are served with an error."
        },
        "remote.log.reader.threads": {
            "type": "integer",
            "enum": [
                10,
                20,
                0
            ],
            "description": "Size of the thread pool that is allocated for handling remote log reads."
        },
        "remote.log.storage.system.enable": {
            "description": "Whether to enable tiered storage functionality in a broker or not. Valid values are `true` or `false` and the\n            default value is false. When it is true broker starts all the services required for the tiered storage\n            functionality.",
            "type": "boolean"
        },
        "replica.fetch.backoff.ms": {
            "type": "integer",
            "enum": [
                1000,
                10000,
                -1
            ],
            "description": "The amount of time to sleep when fetch partition data fails"
        },
        "replica.fetch.max.bytes": {
            "type": "integer",
            "enum": [
                104857600,
                1048576,
                -1
            ],
            "description": "The number of bytes of messages to attempt to fetch"
        },
        "replica.fetch.response.max.bytes": {
            "type": "integer",
            "enum": [
                104857600,
                1048576,
                -1
            ],
            "description": "The maximum bytes in a response for a replica fetch request"
        },
        "reserved.broker.max.id": {
            "description": "Max number that can be used for a broker.id",
            "type": "integer",
            "enum": [
                1000,
                100,
                -1
            ]
        },
        "security.inter.broker.protocol": {
            "description": "Security protocol used to communicate between brokers. Valid values are: PLAINTEXT, SSL, SASL_PLAINTEXT,\n            SASL_SSL. It is an error to set this and inter.broker.listener.name properties at the same time.",
            "type": "string",
            "enum": [
                "PLAINTEXT",
                "SSL",
                "INVALID"
            ]
        },
        "socket.connection.setup.timeout.max.ms": {
            "description": "The maximum amount of time the client will wait for the socket connection to be established. The connection\n            setup timeout will increase exponentially for each consecutive connection failure up to this maximum. To\n            avoid connection storms, a randomization factor of 0.2 will be applied to the timeout resulting in a random\n            range between 20% below and 20% above the computed value.",
            "type": "integer",
            "enum": [
                30000,
                10000,
                0
            ]
        },
        "socket.connection.setup.timeout.ms": {
            "description": "The amount of time the client will wait for the socket connection to be established. If the connection is not\n            built before the timeout elapses, clients will close the socket channel. This value is the initial backoff\n            value and will increase exponentially for each consecutive connection failure, up to the\n            socket.connection.setup.timeout.max.ms value.",
            "type": "integer",
            "enum": [
                10000,
                1000,
                0
            ]
        },
        "socket.listen.backlog.size": {
            "description": "The maximum number of pending connections on the socket. In Linux, you may also need to configure\n            somaxconn and tcp_max_syn_backlog kernel parameters accordingly to make the\n            configuration takes effect.",
            "type": "integer",
            "enum": [
                50,
                100,
                0
            ]
        },
        "ssl.cipher.suites": {
            "description": "A list of cipher suites. This is a named combination of authentication, encryption, MAC and key exchange\n            algorithm used to negotiate the security settings for a network connection using TLS or SSL network\n            protocol. By default all the available cipher suites are supported.",
            "type": "string",
            "enum": [
                "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256",
                "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384",
                "INVALID"
            ]
        },
        "ssl.client.auth": {
            "description": "Configures kafka broker to request client authentication. The following settings are common:\n        \nssl.client.auth=required If set to required client authentication is required.\n            ssl.client.auth=requested This means client authentication is optional. unlike required, if\n                this option is set client can choose not to provide authentication information about itself\n            ssl.client.auth=none This means client authentication is not needed.\n        \n",
            "type": "string",
            "enum": [
                "required",
                "requested",
                "INVALID"
            ]
        },
        "ssl.enabled.protocols": {
            "description": "The list of protocols enabled for SSL connections. The default is 'TLSv1.2,TLSv1.3' when running with Java 11\n            or newer, 'TLSv1.2' otherwise. With the default value for Java 11, clients and servers will prefer TLSv1.3\n            if both support it and fallback to TLSv1.2 otherwise (assuming both support at least TLSv1.2). This default\n            should be fine for most cases. Also see the config documentation for `ssl.protocol`.",
            "type": "string",
            "enum": [
                "TLSv1.2",
                "TLSv1.3",
                "INVALID"
            ]
        },
        "ssl.key.password": {
            "description": "The password of the private key in the key store file or the PEM key specified in 'ssl.keystore.key'.",
            "type": "string",
            "enum": [
                "password",
                "INVALID"
            ]
        },
        "ssl.keymanager.algorithm": {
            "description": "The algorithm used by key manager factory for SSL connections. Default value is the key manager factory\n            algorithm configured for the Java Virtual Machine.",
            "type": "string",
            "enum": [
                "SunX509",
                "INVALID"
            ]
        },
        "ssl.protocol": {
            "description": "The SSL protocol used to generate the SSLContext. The default is 'TLSv1.3' when running with Java 11 or\n            newer, 'TLSv1.2' otherwise. This value should be fine for most use cases. Allowed values in recent JVMs are\n            'TLSv1.2' and 'TLSv1.3'. 'TLS', 'TLSv1.1', 'SSL', 'SSLv2' and 'SSLv3' may be supported in older JVMs, but\n            their usage is discouraged due to known security vulnerabilities. With the default value for this config and\n            'ssl.enabled.protocols', clients will downgrade to 'TLSv1.2' if the server does not support 'TLSv1.3'. If\n            this config is set to 'TLSv1.2', clients will not use 'TLSv1.3' even if it is one of the values in\n            ssl.enabled.protocols and the server only supports 'TLSv1.3'.",
            "type": "string",
            "enum": [
                "TLSv1.2",
                "TLSv1.3",
                "INVALID"
            ]
        },
        "alter.log.dirs.replication.quota.window.num": {
            "description": "The number of samples to retain in memory for alter log dirs replication quotas",
            "type": "integer",
            "enum": [
                10,
                20,
                0
            ]
        },
        "alter.log.dirs.replication.quota.window.size.seconds": {
            "description": "The time span of each sample for alter log dirs replication quotas",
            "type": "integer",
            "enum": [
                60,
                10,
                0
            ]
        },
        "authorizer.class.name": {
            "description": "The fully qualified name of a class that implements\n            org.apache.kafka.server.authorizer.Authorizer interface, which is used by the broker for\n            authorization.",
            "type": "string",
            "enum": [
                "org.apache.kafka.server.authorizer.AclAuthorizer",
                "INVALID"
            ]
        },
        "connection.failed.authentication.delay.ms": {
            "description": "Connection close delay on failed authentication: this is the time (in milliseconds) by which connection close\n            will be delayed on authentication failure. This must be configured to be less than connections.max.idle.ms\n            to prevent connection timeout.",
            "type": "integer",
            "enum": [
                1000,
                10000,
                -1
            ]
        },
        "controller.quorum.retry.backoff.ms": {
            "description": "The amount of time to wait before attempting to retry a failed request to a given topic partition. This\n            avoids repeatedly sending requests in a tight loop under some failure scenarios. This value is the initial\n            backoff value and will increase exponentially for each failed request, up to the\n            retry.backoff.max.ms value.",
            "type": "integer",
            "enum": [
                1000,
                10000,
                0
            ]
        },
        "controller.quota.window.num": {
            "description": "The number of samples to retain in memory for controller mutation quotas",
            "type": "integer",
            "enum": [
                10,
                20,
                0
            ]
        },
        "controller.quota.window.size.seconds": {
            "description": "The time span of each sample for controller mutations quotas",
            "type": "integer",
            "enum": [
                60,
                10,
                0
            ]
        },
        "delegation.token.expiry.check.interval.ms": {
            "description": "Scan interval to remove expired delegation tokens.",
            "type": "integer",
            "enum": [
                60000,
                1000,
                0
            ]
        },
        "kafka.metrics.polling.interval.secs": {
            "description": "The metrics polling interval (in seconds) which can be used in kafka.metrics.reporters implementations.",
            "type": "integer",
            "enum": [
                10,
                1,
                0
            ]
        },
        "kafka.metrics.reporters": {
            "description": "A list of classes to use as Yammer metrics custom reporters. The reporters should implement\n            kafka.metrics.KafkaMetricsReporter trait. If a client wants to expose JMX operations on a\n            custom reporter, the custom reporter needs to additionally implement an MBean trait that extends\n            kafka.metrics.KafkaMetricsReporterMBean trait so that the registered MBean is compliant with\n            the standard MBean convention.",
            "type": "string",
            "enum": [
                "kafka.metrics.KafkaCSVMetricsReporter",
                "INVALID"
            ]
        },
        "listener.security.protocol.map": {
            "description": "Map between listener names and security protocols. This must be defined for the same security protocol to be\n            usable in more than one port or IP. For example, internal and external traffic can be separated even if SSL\n            is required for both. Concretely, the user could define listeners with names INTERNAL and EXTERNAL and this\n            property as: INTERNAL:SSL,EXTERNAL:SSL. As shown, key and value are separated by a colon and\n            map entries are separated by commas. Each listener name should only appear once in the map. Different\n            security (SSL and SASL) settings can be configured for each listener by adding a normalised prefix (the\n            listener name is lowercased) to the config name. For example, to set a different keystore for the INTERNAL\n            listener, a config with name listener.name.internal.ssl.keystore.location would be set. If the\n            config for the listener name is not set, the config will fallback to the generic config (i.e.\n            ssl.keystore.location). Note that in KRaft a default mapping from the listener names defined by\n            controller.listener.names to PLAINTEXT is assumed if no explicit mapping is provided and no\n            other security protocol is in use.",
            "type": "string",
            "enum": [
                "INTERNAL:SSL,EXTERNAL:SSL",
                "SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT",
                "INVALID"
            ]
        },
        "log.dir.failure.timeout.ms": {
            "description": "If the broker is unable to successfully communicate to the controller that some log directory has failed for\n            longer than this time, the broker will fail and shut down.",
            "type": "integer",
            "enum": [
                60000,
                1000,
                0
            ]
        },
        "log.message.downconversion.enable": {
            "description": "This configuration controls whether down-conversion of message formats is enabled to satisfy consume\n            requests. When set to false, broker will not perform down-conversion for consumers expecting an\n            older message format. The broker responds with UNSUPPORTED_VERSION error for consume requests\n            from such older clients. This configurationdoes not apply to any message format conversion that might be\n            required for replication to followers.",
            "type": "boolean"
        },
        "metadata.max.idle.interval.ms": {
            "description": "This configuration controls how often the active controller should write no-op records to the metadata\n            partition. If the value is 0, no-op records are not appended to the metadata partition. The default value is\n            500",
            "type": "integer",
            "enum": [
                500,
                1000,
                -1
            ]
        },
        "metrics.num.samples": {
            "description": "The number of samples maintained to compute metrics.",
            "type": "integer",
            "enum": [
                2,
                1,
                0
            ]
        },
        "metrics.recording.level": {
            "description": "The highest recording level for metrics.",
            "type": "string",
            "enum": [
                "INFO",
                "DEBUG",
                "INVALID"
            ]
        },
        "metrics.sample.window.ms": {
            "description": "The window of time a metrics sample is computed over.",
            "type": "integer",
            "enum": [
                30000,
                1000,
                0
            ]
        },
        "password.encoder.cipher.algorithm": {
            "description": "The Cipher algorithm used for encoding dynamically configured passwords.",
            "type": "string",
            "enum": [
                "AES/CBC/PKCS5Padding",
                "INVALID"
            ]
        },
        "password.encoder.iterations": {
            "description": "The iteration count used for encoding dynamically configured passwords.",
            "type": "integer",
            "enum": [
                4096,
                1024,
                0
            ]
        },
        "password.encoder.key.length": {
            "description": "The key length used for encoding dynamically configured passwords.",
            "type": "integer",
            "enum": [
                128,
                256,
                0
            ]
        },
        "password.encoder.keyfactory.algorithm": {
            "description": "The SecretKeyFactory algorithm used for encoding dynamically configured passwords. Default is\n            PBKDF2WithHmacSHA512 if available and PBKDF2WithHmacSHA1 otherwise.",
            "type": "string",
            "enum": [
                "PBKDF2WithHmacSHA512",
                "PBKDF2WithHmacSHA1",
                "INVALID"
            ]
        },
        "producer.id.expiration.ms": {
            "description": "The time in ms that a topic partition leader will wait before expiring producer IDs. Producer IDs will not\n            expire while a transaction associated to them is still ongoing. Note that producer IDs may expire sooner if\n            the last write from the producer ID is deleted due to the topic's retention settings. Setting this value the\n            same or higher than delivery.timeout.ms can help prevent expiration during retries and protect\n            against message duplication, but the default should be reasonable for most use cases.",
            "type": "integer",
            "enum": [
                300000,
                1000,
                0
            ]
        },
        "quota.window.num": {
            "description": "The number of samples to retain in memory for client quotas",
            "type": "integer",
            "enum": [
                10,
                20,
                0
            ]
        },
        "quota.window.size.seconds": {
            "description": "The time span of each sample for client quotas",
            "type": "integer",
            "enum": [
                60,
                10,
                0
            ]
        },
        "remote.log.index.file.cache.total.size.bytes": {
            "description": "The total size of the space allocated to store index files fetched from remote storage in the local storage.\n        ",
            "type": "integer",
            "enum": [
                1073741824,
                1048576,
                0
            ]
        },
        "remote.log.manager.task.interval.ms": {
            "description": "Interval at which remote log manager runs the scheduled tasks like copy segments, and clean up remote log\n            segments.",
            "type": "integer",
            "enum": [
                30000,
                1000,
                0
            ]
        },
        "remote.log.metadata.custom.metadata.max.bytes": {
            "description": "The maximum size of custom metadata in bytes that the broker should accept from a remote storage plugin. If\n            custom metadata exceeds this limit, the updated segment metadata will not be stored, the copied data will be\n            attempted to delete, and the remote copying task for this topic-partition will stop with an error.",
            "type": "integer",
            "enum": [
                1048576,
                10485760,
                -1
            ]
        },
        "replication.quota.window.num": {
            "description": "The number of samples to retain in memory for replication quotas",
            "type": "integer",
            "enum": [
                10,
                20,
                0
            ]
        },
        "replication.quota.window.size.seconds": {
            "description": "The time span of each sample for replication quotas",
            "type": "integer",
            "enum": [
                60,
                10,
                0
            ]
        },
        "ssl.allow.dn.changes": {
            "description": "Indicates whether changes to the certificate distinguished name should be allowed during a dynamic\n            reconfiguration of certificates or not.",
            "type": "boolean"
        },
        "ssl.allow.san.changes": {
            "description": "Indicates whether changes to the certificate subject alternative names should be allowed during a dynamic\n            reconfiguration of certificates or not.",
            "type": "boolean"
        },
        "ssl.endpoint.identification.algorithm": {
            "description": "The endpoint identification algorithm to validate server hostname using server certificate. ",
            "type": "string",
            "enum": [
                "HTTPS",
                "INVALID"
            ]
        },
        "ssl.principal.mapping.rules": {
            "description": "A list of rules for mapping from distinguished name from the client certificate to short name. The rules are\n            evaluated in order and the first rule that matches a principal name is used to map it to a short name. Any\n            later rules in the list are ignored. By default, distinguished name of the X.500 certificate will be the\n            principal. For more details on the format please see  security authorization and\n                acls. Note that this configuration is ignored if an extension of KafkaPrincipalBuilder is provided\n            by the principal.builder.class configuration.",
            "type": "string",
            "enum": [
                "DEFAULT",
                "INVALID"
            ]
        },
        "telemetry.max.bytes": {
            "description": "The maximum size (after compression if compression is used) of telemetry metrics pushed from a client to the\n            broker. The default value is 1048576 (1 MB).",
            "type": "integer",
            "enum": [
                1048576,
                10485760,
                0
            ]
        },
        "transaction.abort.timed.out.transaction.cleanup.interval.ms": {
            "description": "The interval at which to rollback transactions that have timed out",
            "type": "integer",
            "enum": [
                60000,
                1000,
                0
            ]
        },
        "transaction.partition.verification.enable": {
            "description": "Enable verification that checks that the partition has been added to the transaction before writing\n            transactional records to the partition",
            "type": "boolean"
        },
        "transaction.remove.expired.transaction.cleanup.interval.ms": {
            "description": "The interval at which to remove transactions that have expired due to\n            transactional.id.expiration.ms passing",
            "type": "integer",
            "enum": [
                60000,
                1000,
                0
            ]
        }
    }
}